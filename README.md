# Norm-Inference-in-Social-Dilemmas-an-Inverse-Reinforcement-Learning-Approach
This project is part of a Master's dissertation with the homonymous name.

## Abstract
Cooperation is an important tool for humans, crucial to reach optimal
and ethical behaviour in many contexts. Multi-agent Reinforcement
Learning techniques are an excellent instrument for studying the emerging
cooperative behaviour of AI agents in different environments that can
be simulated through games, which can be considered simplifications of
the real world. Some of the most studied cases are Social Dilemmas,
such as the Common Pool Resource Problem, where the cooperation or
defection of the agents is crucial to the outcomes of the collective and
the individuals.
The latest research has led to a good performance of the cooperation
between AI agents. However, another critical characteristic agents need
is Norm Inference, which is the ability to identify and understand the
social norms that govern behaviour in a society. It is a serious aspect
that must be considered when designing them since artificial learning
agents will likely be embodied in our future society and will need to
interact with both humans and non-human agents.
In this dissertation, an Inverse Reinforcement Learning (IRL) approach
is used on the problem of Norm Inference in a Common Pool
Resource problem, where the norm of private areas has been established.
It is shown how it is possible to recover the expert policy that follows
the norm through IRL and how the recovered reward function can be
informative about the norm.
